### 2 Document the microservice architeture and components/tools/dependencies
- Spring Cloud
- Zuul API Gateway
- Eureka
- Ribbon Load Balancer
- Hystrix Circuit Breaker
- Config Server
- Kafka
- Docker

### 3 What are Resilience patterns? What is circuit breaker?
Resiliency patterns are a type of service architecture that help to prevent cascading failures and to preserve functionality in the event of service failure. Common resiliency patterns used in application development include the bulkhead pattern and circuit breaker pattern.  
The Circuit Breaker pattern prevents an application from performing an operation that is likely to fail. An application can combine these two patterns by using the Retry pattern to invoke an operation through a circuit breaker.

### 4 Read this article, then list the important questions, then write your answers
1. Write main components of Microservices.
- Containers, Clustering, and Orchestration
- IaC [Infrastructure as Code Conception]
- Cloud Infrastructure
- API Gateway
- Enterprise Service Bus
- Service Delivery
2. What are the benefits and drawbacks of Microservices?
Benefits:  
- Self-contained, and independent deployment module.
- Independently managed services.   
- In order to improve performance, the demand service can be deployed on multiple servers.   
- It is easier to test and has fewer dependencies.  
- A greater degree of scalability and agility.   
- Simplicity in debugging & maintenance.  
- Better communication between developers and business users.   
- Development teams of a smaller size.
Drawbacks:
- Due to the complexity of the architecture, testing and monitoring are more difficult.  
- Lacks the proper corporate culture for it to work.   
- Pre-planning is essential.  
- Complex development.  
- Requires a cultural shift.  
- Expensive compared to monoliths.   
- Security implications.
- Maintaining the network is more difficult.
        
### 5 how to do load balance in microservice? Write a long Summary by yourself.
- Round-robin Load Balancing: With round-robin load balancing, requests are distributed in a round-robin fashion across the different instances of a service. This approach is simple and easy to implement, but it may not be the most effective way to balance the load, especially if the instances have different capabilities.
- Weighted Load Balancing: Weighted load balancing involves assigning a weight to each instance of a service based on its capabilities and load. The load balancer then distributes the requests to the instances based on their weights. This approach allows for more effective load balancing, as it takes into account the capabilities of each instance. 
- Least Connection Load Balancing: With least connection load balancing, the load balancer directs requests to the instance with the fewest active connections. This approach is effective at balancing the load across instances, but it requires more complex monitoring of the instances' connections.
- IP Hash Load Balancing: IP hash load balancing involves using the IP address of the client to determine which instance of a service to direct the request to. This approach ensures that requests from the same client are always directed to the same instance of the service, which can be useful for session management and other scenarios.
- Dynamic Load Balancing: Dynamic load balancing involves monitoring the load on each instance of a service and adjusting the load balancing strategy dynamically. This approach can be highly effective at balancing the load across instances, but it requires more complex monitoring and management infrastructure.

### 6 How to do service discovery?
When using Client-Side Discovery, the Service Consumer is responsible for determining the network locations of available service instances and load balancing requests between them. The client queries the Service Register. Then the client uses a load-balancing algorithm to choose one of the available service instances and performs a request.  
The alternate approach to Service Discovery is the Server-Side Discovery model, which uses an intermediary that acts as a Load Balancer. The client makes a request to a service via a load balancer that acts as an orchestrator. The load balancer queries the Service Registry and routes each request to an available service instance.

### 7 What are the major components of Kafka?
Kafka architecture is made up of topics, producers, consumers, consumer groups, clusters, brokers, partitions, replicas, leaders, and followers.

### 8 What do you mean by a Partition in Kafka?
Partitioning is what enables messages to be split in parallel across several brokers in the cluster.

### 9 What do you mean by zookeeper in Kafka and what are its uses?
Zookeeper is used for metadata management in the Kafka world. For example: Zookeeper keeps track of which brokers are part of the Kafka cluster. Zookeeper is used by Kafka brokers to determine which broker is the leader of a given partition and topic and perform leader elections.

### 10 Can we use Kafka without Zookeeper?
 In the latest release, ZooKeeper can be replaced by an internal Raft quorum of controllers.
 
### 11 Explain the concept of Leader and Follower in Kafka.
In Kafka, each partition has one server that acts as a Leader and one or more servers that operate as Followers. The Leader is in charge of all read and writes requests for the partition, while the Followers are responsible for passively replicating the leader. In the case that the Leader fails, one of the Followers will assume leadership. The server's load is balanced as a result of this.

### 12 Why is Topic Replication important in Kafka? What do you mean by ISR in Kafka?
The purpose of adding replication in Kafka is for stronger durability and higher availability. We want to guarantee that any successfully published message will not be lost and can be consumed, even when there are server failures.  
An in-sync replica (ISR) is a broker that has the latest data for a given partition. A leader is always an in-sync replica. A follower is an in-sync replica only if it has fully caught up to the partition it's following. In other words, it can't be behind on the latest records for a given partition.

### 13 What do you understand about a consumer group in Kafka?
A consumer group is a set of consumers which cooperate to consume data from some topics. The partitions of all the topics are divided among the consumers in the group. As new group members arrive and old members leave, the partitions are re-assigned so that each member receives a proportional share of the partitions.

### 14 How do you start a Kafka server?
- Install Apache Kafka.
- Start Apache Zookeeper.
- Start the Kafka server.

### 15 Tell me about some of the real-world usages of Apache Kafka.
Log Aggregation. Stream Processing. Event Sourcing. Commit Log.

### 16 Describe partitioning key in Kafka.
In Kafka, the hash base partition is used to identify the partition id (as per the provided key). If we haven't set it or keep it as null in the environment, then the Kafka producer will pick any random partition and keep the messages or data into it.

### 17 What is the purpose of partitions in Kafka?
Partitioning is what enables messages to be split in parallel across several brokers in the cluster.

### 18 Differentiate between Rabbitmq and Kafka.
RabbitMQ sends and queues messages in a specific order. Unless a higher priority message is queued into the system, consumers receive messages in the order they were sent. Meanwhile, Kafka uses topics and partitions to queue messages. When a producer sends a message, it goes into a specific topic and partition.

### 19 What are the guarantees that Kafka provides?
In Kafka, order can only be guaranteed within a partition. This means that if messages were sent from the producer in a specific order, the broker will write them to a partition and all consumers will read from that in the same order.

### 20 What do you mean by an unbalanced cluster in Kafka? How can you balance it?
The broker configuration auto.leader.rebalance.enable=true allows the controller node to reassign leadership back to the preferred replica leaders and thereby restore the even distribution.  
Running Kafka-preferred-replica-election.sh forces the election of the preferred replica for all partitions: The tool takes a mandatory list of zookeeper hosts and an optional list of topic partitions provided as a JSON file. If the list is not provided, the tool queries zookeeper and gets all the topic partitions for the cluster. It might be a tedious task to run the Kafka-preferred-replica-election.sh tool. Customized scripts can render only the necessary topics and their partitions and automate the process across the cluster.

### 21 In your recent project, are you a producer or consumer or both?
producer

### 22 In your recent project, Could you tell me your topic name?
The topic name can be up to 255 characters in length, and can include the following characters: a-z, A-Z, 0-9, . (dot), _ (underscore), and - (dash). The topic name can be changed dynamically by setting a local environment override.

### 23 In your recent project, How many brokers do you have? How many partitions for each topic? How many data for each topic.
For most implementations you want to follow the rule of thumb of 10 partitions per topic, and 10,000 partitions per Kafka cluster. Going beyond that amount can require additional monitoring and optimization.

### 25 What is offset?
The offset is a unique ID assigned to the partitions, which contains messages. The most important use is that it identifies the messages through ID, which are available in the partitions. In other words, it is a position within a partition for the next message to be sent to a consumer.
