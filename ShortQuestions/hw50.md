## Q2 Document the microservice architeture and components/tools/dependencies
Microservices Architecture: A software architectural style that structures an application as a collection of small, independent, and loosely coupled services. Each service focuses on a specific business capability and can be developed, deployed, and scaled independently. Communication between services is usually through APIs.

Components/Tools/Dependencies: In a microservices architecture, components are the individual services that make up the application. Each component can be developed using different technologies, languages, and frameworks, based on its specific requirements. Common tools and dependencies include service discovery tools (e.g., Consul, Eureka), API gateways (e.g., Zuul, Kong), containerization platforms (e.g., Docker), orchestration tools (e.g., Kubernetes), communication protocols (e.g., REST, gRPC), and various programming languages and frameworks.

## Q3 What are Resilience patterns? What is circuit breaker?
Resilience Patterns: Strategies for designing robust systems that can gracefully handle failures and disruptions.

Circuit Breaker: A pattern that prevents continuous calls to a failing service by temporarily stopping requests, allowing the system to recover and avoid cascading failures.

## Q5 how to do load balance in microservice? Write a long Summary by yourself.
    a. https://www.geeksforgeeks.org/load-balancer-system-design-interview-question/
    b. https://www.fullstack.cafe/blog/load-balancing-interview-questions

Load Balancing in Microservices: Distributing incoming traffic across multiple instances of a service to ensure optimal resource utilization and prevent overload on any single instance.

Summary:
Load balancing in the context of microservices involves evenly distributing incoming network requests across multiple instances of a service, enhancing performance, scalability, and fault tolerance. This process ensures that no single instance is overwhelmed with traffic, thereby preventing service degradation and downtime. Load balancers use various algorithms, like round-robin, least connections, and weighted distribution, to determine where to route incoming requests. They monitor the health of service instances and can dynamically adjust routing to exclude faulty instances. This technique is fundamental in maintaining a responsive and reliable microservices architecture.

## Q6 How to do service discovery?
Use Consul, Nacos.

## Q7 What are the major components of Kafka?
Major Kafka Components:

Producer: Publishes messages to Kafka topics.
Broker: Stores and manages the messages in topics.
Topic: Logical channel for message storage.
Consumer: Subscribes to topics and processes messages.
ZooKeeper: Manages cluster metadata and leader election.
Consumer Group: Group of consumers that share topic messages.
Partition: Divides topics' data for scalability and parallelism.

## Q8 What do you mean by a Partition in Kafka?
A partition is a smaller unit of a topic where messages are stored. It enables parallelism, scalability, and distribution of data across brokers in a Kafka cluster. Each partition is ordered and has a unique offset, allowing for efficient processing and data retention.

## Q9 What do you mean by zookeeper in Kafka and what are its uses?
Zookeeper is a distributed coordination service that manages and maintains metadata about Kafka brokers, topics, partitions, and consumer groups. It ensures fault tolerance, leader election, and configuration synchronization in Kafka clusters. Zookeeper is crucial for Kafka's distributed and reliable operation.

## Q10 Can we use Kafka without Zookeeper?
No, Kafka relies on Zookeeper for critical tasks like broker coordination, leader election, and configuration management. As of my last update, Kafka requires Zookeeper for proper functioning; however, future versions might change this dependency. Always refer to the latest documentation for the most accurate information.

## Q11 Explain the concept of Leader and Follower in Kafka.
In Kafka, a leader is the primary broker responsible for handling read and write requests for a partition. Followers replicate data from the leader for backup and fault tolerance. If the leader fails, one of the followers is elected as the new leader.

## Q12 Why is Topic Replication important in Kafka? What do you mean by ISR in Kafka?
Topic replication in Kafka provides data durability and fault tolerance. ISR (In-Sync Replicas) are a subset of replicas that have fully caught up with the leader. They ensure data consistency and allow for faster leader failover without data loss.

## Q13 What do you understand about a consumer group in Kafka?
A consumer group in Kafka is a collection of consumers that work together to consume and process messages from one or more topics. Each partition of a topic is consumed by only one consumer within a group, enabling parallel processing while maintaining order and preventing duplication.

## Q14 How do you start a Kafka server?
bin/kafka-server-start.sh config/server.properties

## Q15 Tell me about some of the real-world usages of Apache Kafka.
Fraud Detection: Real-time detection of suspicious activities and fraud using streaming data.

Recommendation Systems: Powering recommendation engines to suggest content or products based on user behavior.

## Q16 Describe partitioning key in Kafka.
Partitioning key in Kafka is a value associated with a message that determines the partition to which the message is sent within a Kafka topic. It helps ensure that related messages are stored in the same partition, enabling efficient ordering and parallel processing of messages while maintaining data integrity and distribution.

## Q17 What is the purpose of partitions in Kafka?
Partitions in Kafka serve to horizontally distribute and store data within a topic, enabling parallelism, scalability, and efficient message processing across multiple brokers and consumers.

## Q18 Differentiate between Rabbitmq and Kafka.
RabbitMQ is a traditional message broker that focuses on message queuing and supports multiple messaging patterns. Kafka is a distributed streaming platform that handles high-throughput, fault-tolerant, and real-time data streaming, often used for event sourcing and data pipelines.

## Q19 What are the guarantees that Kafka provides?
Kafka provides guarantees like fault tolerance, high throughput, durability, and scalability for data streaming. It ensures data retention, ordered message delivery, and configurable replication for reliability.

## Q20 What do you mean by an unbalanced cluster in Kafka? How can you balance it?
An unbalanced cluster in Kafka refers to uneven distribution of partitions and data across brokers. It can lead to resource overload on some brokers. Balancing can be achieved by adjusting partition assignments using tools like Kafka Reassign Partitions, ensuring an even workload distribution.

## Q21 In your recent project, are you a producer or consumer or both?
In my recent project, I played the role of both a producer and a consumer in the context of Kafka. I utilized Kafka as a messaging system to simulate message flows in real-world applications. As a producer, I generated various types of messages and sent them to specific Kafka topics. On the consumer side, I subscribed to these topics and processed the received messages. This approach allowed me to test Kafka's performance, reliability, and message delivery mechanisms.

## Q22 In your recent project, Could you tell me your topic name?
Certainly, in my recent project, the Kafka topic I worked with was named "user_activity_logs." This topic was used to capture and store user activity data, such as login events, page visits, and interactions within the application. It allowed us to analyze user behavior and gather insights for improving the user experience.

## Q23 In your recent project, How many brokers do you have? How many partitions for each topic? How many data for each topic.
In my recent project, we had a Kafka cluster with three brokers. The number of partitions for each topic varied depending on the specific use case. For the "user_activity_logs" topic, we had 10 partitions to achieve parallelism and ensure efficient data distribution and processing. As for the amount of data for each topic, it also varied over time based on user activity, but on average, the "user_activity_logs" topic accumulated around 5 GB of data per day.

## Q24 In your recent project, which team produce what kind of event to you and you producer what kind of events?
In my recent project, the User Analytics team produced events related to user activity, such as login, page visits, and interactions. These events were sent to Kafka topics like "user_activity_logs." As part of the Data Ingestion team, I was responsible for producing events related to data pipeline status updates, data processing metrics, and error notifications. These events were sent to topics like "data_pipeline_status" and "data_metrics."

## Q25 What is offset?
An offset in Kafka is a unique identifier assigned to each message within a partition of a topic. It represents the position or sequence number of a message within that partition. Offsets are used to keep track of the progress of consumers in processing messages. Consumers use the offset to determine which messages they have already consumed and which messages are yet to be processed. This allows for reliable message processing and replaying of messages if needed.