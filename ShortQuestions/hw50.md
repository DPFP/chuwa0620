# 2. Document the microservice architeture and components/tools/dependencies
- Spring Cloud
- Zuul API Gateway
- Eureka
- Ribbon Load Balancer
- Hystrix Circuit Breaker
- Config Server
- Kafka
- Docker

# 3.  What are Resilience patterns? What is circuit breaker?
Resilience patterns are design principles and techniques used in software architecture to enhance the reliability, stability, and fault tolerance of systems, especially in distributed and microservices environments. These patterns help applications gracefully handle and recover from failures, prevent cascading failures, and maintain acceptable performance even in the face of unexpected issues.

The Circuit Breaker pattern is a software design pattern that helps prevent the repeated and continuous execution of a failing operation. It acts as a safety mechanism to stop sending requests to a service that is experiencing issues, thus preventing the system from becoming overwhelmed with failing requests.

# 4.  Read this article, then list the important questions, then write your answers

## Write main features of Microservices.
- Decoupling
- Componentization
- Business Capabilities
- Team Autonomy
- Continuous Delivery
- Responsibility
- Decentralized Governance
- Agility

## Write difference between Monolithic, SOA and Microservices Architecture.
- Monolithic Architecture: all the software components of an application are bundled together tightly.  It is usually built as one large system and is one code-base. 
- Service-Oriented Architecture: a group of services interacting or communicating with each other.
- Microservice Architecture: structuring an application in the form of a cluster of small, autonomous services modeled around a business domain

## What are the challenges that one has to face while using Microservices?
- Require heavy infrastructure setup. 
- Need Heavy investment. 
- Require excessive planning to handle or manage operations overhead.
- Microservices are always interdependent. Therefore, they must communicate with each other.   
- It is a heavily involved model because it is a distributed system.   


# 5.  how to do load balance in microservice? Write a long Summary by yourself.
- Add load balancer in front of web servers, between application server and cache server, between cache server and DB server.
- Apply load balancing techniques like round robin, session affinity or sticky session and IP Address affinity.
round robin: going down the list of servers in the group, the roundâ€‘robin load balancer forwards a client request to each server in turn. When it reaches the end of the list, the load balancer loops back and goes down the list again

Session affinity: The machine is associated with a session as soon as the session is created. All the requests in a particular session are always redirected to the associated machine. 

IP Address affinity: directing incoming requests from the same client IP address to the same backend server or instance for the duration of a session. This technique is commonly used to ensure that user sessions, which may store important data or context, remain consistent and don't get disrupted when interacting with a distributed system that employs load balancers.

# 6.  How to do service discovery?
It allows services to dynamically locate and communicate with each other without hardcoding IP addresses or endpoints. It enables seamless interaction between services as they scale, deploy, and change over time.

# 7. What are the major components of Kafka?
- Broker
- Topic
- Partition
- Producer
- Consumer
- Consumer Group
- Zookeeper
- Offsets
- Replication
- Connector
- Streams

# 8.  What do you mean by a Partition in Kafka?
A partition is a fundamental concept in Kafka that allows data within a topic to be distributed and processed in parallel. Each topic can be divided into one or more partitions.

# 9.  What do you mean by zookeeper in Kafka and what are its uses?
ZooKeeper is a distributed coordination service for managing and maintaining metadata about Kafka clusters, brokers, topics, and partitions. It provides functionalities like distributed synchronization, configuration management, and leader election. 

# 10. Can we use Kafka without Zookeeper?
In recent versions of Apache Kafka, efforts have been made to reduce Kafka's dependency on ZooKeeper and to move toward a self-managed architecture. Kafka now includes its internal metadata management, called the Kafka Controller, which takes over many of the responsibilities that were previously handled by ZooKeeper.

# 11. Explain the concept of Leader and Follower in Kafka.
The leader is the primary broker responsible for handling all read and write requests for a specific partition. Producers send messages to the leader, and consumers read messages from the leader. 

# 12. Why is Topic Replication important in Kafka? What do you mean by ISR in Kafka?
It provides data redundancy, fault tolerance, and high availability. Replication ensures that data is not lost if a broker or hardware fails. Each partition in a topic can be replicated across multiple brokers.

# 13. What do you understand about a consumer group in Kafka?
It enables parallel and scalable processing of data by allowing multiple consumers to work together to consume messages from one or more topics.

# 14. How do you start a Kafka server?
1. Install Kafka
2. Configure Kafka
3. Start Kafka server

# 15. Tell me about some of the real-world usages of Apache Kafka.
- Log Aggregation
- Event Sourcing
- Real-time data processing
- Microservice Communiation

# 16. Describe partitioning key in Kafka.
a partitioning key is a field within a message that is used to determine the partition to which the message will be assigned in a Kafka topic. 

# 17.  What is the purpose of partitions in Kafka?
- Partitions enable horizontal scalability. 
- Multiple consumers can read messages from different partitions of the same topic in parallel. This allows for efficient and balanced data processing.
- Partitions can be replicated across multiple brokers. If a broker or hardware fails, another replica can take over

# 18. Differentiate between Rabbitmq and Kafka.
RabbitMQ follows the Advanced Message Queuing Protocol (AMQP) and primarily implements a traditional message queue model.It focuses on reliable message delivery and supports features like message acknowledgment, publisher confirms, and transactions.  
Kafka is designed as a distributed streaming platform and follows the publish-subscribe model. It allows for high-throughput, low-latency streaming of data and emphasizes log-based storage and real-time data processing.

RabbitMQ's messages are sent from producers to exchanges, which route them to queues. Consumers then retrieve messages from the queues.  
Kafka topics act as streams of records, and producers publish messages to these topics. Consumers subscribe to topics and read records in real-time

RabbitMQ's often best suited for scenarios with moderate message volumes. Clustering is used for high availability.  
Kafka is designed for high scalability and can handle massive volumes of data. It horizontally scales by distributing data across multiple brokers and partitions.

# 19. What are the guarantees that Kafka provides?
- Durability and Persistence
- Fault Tolerance
- Message Order and Idempotence
- Exactly Once Semantics
- At Least Once Delivery
- Consumer Offsets
- High Throughput and Low Latency
- Retention Policies

# 20. What do you mean by an unbalanced cluster in Kafka? How can you balance it?
n unbalanced cluster in Kafka refers to a situation where the distribution of data and processing load across the Kafka brokers and partitions is uneven. In an unbalanced cluster, some brokers or partitions may be handling significantly more traffic or data than others.  
To balance it:  
Repartitioning  
Scaling Brokers  
Topic Configuration  
Select different keys  
Adjust consumer groups

# 21. In your recent project, are you a producer or consumer or both? 22. In your recent project, Could you tell me your topic name?
As a producer, I developed an order processing module that generates events whenever a customer places an order. Each event includes order details such as customer ID, product IDs, quantity, and timestamp. These events are produced to a Kafka topic called "orders."

# 23. In your recent project, How many brokers do you have? How many partitions for each topic? How many data for each topic.
I had 3 brokers for fault tolerance and performance.  
Each topic, such as "posts," "likes," and "comments," is configured with 5 partitions for efficient parallel processing.  
On average, each partition contains data from approximately 1,000 user interactions per minute.

# 24. In your recent project, which team produce what kind of event to you and you producer what kind of events?

**User Interaction Team (Producer):**
This team is responsible for producing events related to user interactions on the social media platform.
They produce events such as "post_created," "like_given," and "comment_added" to the respective Kafka topics.

**Analytics Team (Producer):**
The analytics team produces events based on aggregated data and insights.
They produce events like "popular_post_trend," "user_engagement_summary," and "daily_activity_report" to specialized Kafka topics for analysis.

**Recommendation Engine Team (Producer):**
The recommendation engine team produces events to improve user experience.
They produce events like "recommended_friends," "similar_posts," and "trending_topics" to Kafka topics used for personalized recommendations.

# 25. What is offset?
an offset is a unique identifier that represents the position of a consumer within a partition of a topic. It is a critical component of Kafka's messaging model.