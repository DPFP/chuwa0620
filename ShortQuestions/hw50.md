1. See Annotation.md

2.  Component

   1. Eureka: Service Discovery Service
   2. Ribbon: Dynamic Routing and load balancer
   3. Zuul: Api Gateway
   4. Hystrix: Circuit breaker

3. Resiliency patterns are **a type of service architecture that help to prevent cascading failures and to preserve functionality in the event of service failure**. Circuit Breaker is a useful resilience pattern that **allows the application to handle failures and prevent cascading failures by breaking the connection to the failing service**.

4. What issue are generally solved by spring clouds?

   1. **Complicated issues caused by distributed systems:** This includes network issues, latency problems, bandwidth problems, and security issues. 
   2. **Service Discovery issues:** Service discovery allows processes and services to communicate and locate each other within a cluster. 
   3. **Redundancy issues:** Distributed systems can often have redundancy issues. 
   4. **Load balancing issues:** Optimize the distribution of workloads among multiple computing resources, including computer clusters, central processing units, and network links. 
   5. **Reduces performance issues:** Reduces performance issues caused by various operational overheads.

5. Load balancer are supposed to solve single point of failure issue and overloaded the server. it can minimized server response time and maximize throughput. Load balance could be placed in several position: between client and server,  between web server and  job server, between application and cache server, or between cache server and database. There are several type of load balancer, software balancer in clients, in service, or hardware balancer.

6. In Spring cloud architecture, this service discovery are implemented by service registry and discovery service like eureka or narcos.

7. Kafka architecture is made up of **topics, producers, consumers, consumer groups, clusters, brokers, partitions, replicas, leaders, and followers**

8.  Partitioning is **what enables messages to be split in parallel across several brokers in the cluster**

9. Zookeeper is **used for metadata management in the Kafka world**. For example: Zookeeper keeps track of which brokers are part of the Kafka cluster. Zookeeper is used by Kafka brokers to determine which broker is the leader of a given partition and topic and perform leader elections. Zookeeper sends notifications to Kafka in case of changes (e.g. new topic, broker dies, broker comes up, delete topics, etc.â€¦)

10. **Kafka provides an option to run without ZooKeeper**, using a feature called Kafka Raft Metadata mode.

11.  **The leader handles all incoming read and write requests for that specific partition, while the followers replicate the data from the leader passively**.

12. **The purpose of adding replication in Kafka is for **stronger durability and higher availability**.  Kafka considers that a record is committed when all replicas in the In-Sync Replica set (ISR) have confirmed that they have taking the record into account**

13. A consumer group is **a set of consumers which cooperate to consume data from some topics**. 

14. Starting Zookeeper and Kafka. Testing Kafka by Creating a Topic. 

15. Kafka is a stream processing system used for **messaging, website activity tracking, metrics collection and monitoring, logging, event sourcing, commit logs, and real-time analytics**.

16. A producer can use a partition key to direct messages to a specific partition. A partition key can be **any value that can be derived from the application context**. 

17.  Partitioning is what **enables messages to be split in parallel across several brokers in the cluster**.

18. RabbitMQ sends and queues messages in a specific order. Unless a higher priority message is queued into the system, consumers receive messages in the order they were sent. Meanwhile, Kafka uses topics and partitions to queue messages. When a producer sends a message, it goes into a specific topic and partition.

19. At most once: Messages are delivered once, and if there is a system failure, messages may be lost and are not redelivered.

    At least once: This means messages are delivered one or more times. ...

    Exactly once: This is the preferred behavior in that each message is delivered once and only once.

20. When some node in the cluster went offline, leader will assign all the job towards alive nodes, when offline nodes go online again, there will be redundancy.  Config leader rebalance or force election on kafka again.

21. In my recent project, our project is just consumer, we need to monitor the user registration and grant them access to the sub system

22. "user_registration"

23.  In my recent project 3 broker and 3 partition, we have corresponding number of broker and partition to maximize throughput and balance the resource. 

24. In my recent project, user management team will  produce user registration event and user privilege change event. 

25. Offset is that for each consumer which let consumer knows the position of current event in the entire message queue. 